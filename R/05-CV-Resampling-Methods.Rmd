---
title: "Cross-Validation Resampling Methods"
author: "Justin M Shea"
date: ''
output:
  pdf_document: default
  html_document: default
---

Resampling Methods
================

We are going to use the Auto data from the `ISLR` package to illustrate various re-sampling methods. 

```{r}
library(ISLR)
data(Auto)
```

```{r, eval=FALSE}
?Auto
```
```{r, tidy=TRUE}
dim(Auto)
names(Auto)
```

A plot is always a nice place to start with a new data set.
```{r, tidy=TRUE}
plot(mpg ~ horsepower, data = Auto)
```



## The Leave-One-Out Cross-Validation (LCOOV) method.

First, lets run a `glm` model on the `Auto` data set.

```{r}
glm_auto <- glm(mpg ~ horsepower, data = Auto)
```

Next, load the `boot` package and check out the documentation for the Cross-validation for Generalized Linear Models function, or `cv.glm`.

```{r}
library(boot)
```
```{r, eval=FALSE}
?cv.glm
```

Then, apply `cv.glm` function to the `Auto` data set, using `glm_auto` model,
returning the delta parameter.

```{r}
cv.glm(Auto, glm_auto)$delta 
```

We can speed up the results by writing a function to use the formula displayed in section 5.2 (pg. 180) and then pass the `glm_auto` model to it.

```{r}
loocv <- function(x){
          h <- lm.influence(x)$h
        mean((residuals(x)/(1-h))^2)
}
```

Is our new function faster? We can use the `system.time` function to compare both methods.

```{r}
system.time(
cv.glm(Auto, glm_auto)$delta 
)

system.time(
loocv(glm_auto)
)
```

\newpage

Next, lets use a `for` loop to efficiently create 5 new polynomial versions of the previous model, regressing `horsepower` against `mpg` and see if the results improve as polynomial order increases.

```{r}
cv.error <- rep(0, 5)
degree <- 1:5

for(d in degree){
  glm.fit <- glm(mpg ~ poly(horsepower, d), data = Auto)
  cv.error[d] <- loocv(glm.fit)
}

plot(degree, cv.error, type = "b", col = "blue", pch = 16,
     main = "LOOCV", xlab = "Degree of Polynomial")
```

\newpage

## The10-fold Cross-Validation

First, initially the cv.error10 vector and ten run the loop.
```{r}
cv.error10 <- rep(0, 5)

for(d in degree){
  glm.fit <- glm(mpg ~ poly(horsepower, d), data = Auto)
  cv.error10[d] <- cv.glm(Auto, glm.fit, K=10)$delta[1]
}

plot(degree, cv.error, type = "b", col = "blue", pch = 16, 
     main = "10 Fold CV", xlab = "Degree of Polynomial")
lines(degree, cv.error10, type = "b", col = "red", pch = 16)
```

## Bootstrap

Suppose that we wish to invest a fixed. sum of money in two financial assets that yield returns of X and Y, where X and Y are random quantities. We will invest a fraction of our money in X, and will invest the remaining $1 - \alpha$ in Y. We wish to choose $\alpha$ to minimize the total risk, or variance, of our investment. In other words, we want to minimize $Var(\alpha X + (1-\alpha)Y)$. One can show that the value that minimizes the risk is given by

$$\alpha = \frac{\sigma^2_Y - \sigma_{XY}}{\sigma^2_X + \sigma^2_Y - 2\sigma_{XY}}$$

where $\sigma^2_X = Var(X)$, $\sigma^2_Y = Var(Y)$, and $\sigma_{XY} = Cov(X,Y)$.

However, the values of $\sigma^2_X$, $\sigma^2_Y$, and  $\sigma_{XY}$ are unkown.
We can compute estimates for these quantities, $\hat\sigma^2_X$, $\hat\sigma^2_Y$, and  $\hat\sigma_{XY}$, using a data set that contains measurments for $X$ and $Y$.

We can then estimate the value of $\alpha$ that minimizes the variance of our investment using:

$$\hat\alpha = \frac{\hat\sigma^2_Y - \hat\sigma_{XY}}{\hat\sigma^2_X + \hat\sigma^2_Y - 2\hat\sigma_{XY}}$$

Load the `Portfolio` data set from the `ISLR` package, containing 100 returns for two assets, X and Y.

```{r}
data("Portfolio")
```

```{r}
plot(Y ~ X, data = Portfolio, col = "darkgreen", type = "p", pch = 16)
```

```{r}
alpha <- function(x, y) {
        
          var_x <- var(x)
          var_y <- var(y)
          cov_xy <- cov(x, y)
          
(var_y - cov_xy)/(var_x + var_y - 2 *cov_xy)
          
}

alpha(Portfolio$X, Portfolio$Y)
```

So what is the standard error of alpha?
First, lets make a wrapper function

```{r}
alpha2 <- function(data, index){
                   with(data[index, ], alpha(X, Y))
}

alpha2(Portfolio, 1:100)

set.seed(1)
alpha2(Portfolio, sample(1:100, 100, replace = TRUE))

boot.out <- boot(Portfolio, alpha2, R = 1000)

boot.out$t0
```

Finally, plot the bootstrap model object.
```{r}
plot(boot.out)
```
