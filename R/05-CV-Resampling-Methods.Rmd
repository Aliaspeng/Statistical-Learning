---
output:
  pdf_document: default
  html_document: default
---

Resampling Methods
================

We are going to use the Auto data to illustrate the results of various resampling methods, so lets load it from the `ISLR` package and explore. 

```{r}
library(ISLR)
data(Auto)
```
```{r, tidy=TRUE}
str(Auto[,-9])
```

A plot is always a nice place to start with a new data set.
```{r, tidy=TRUE}
plot(mpg ~ horsepower, data = Auto)
```

As is exploring the available documentation. 
```{r, eval=FALSE}
?Auto
```

## The Leave-One-Out Cross-Validation (LCOOV) method.

First, lets run a `glm` model on the `Auto` data set.

```{r}
glm_auto <- glm(mpg ~ horsepower, data = Auto)
```

Next, load the `boot` package and check out the documentation for the Cross-validation for Generalized Linear Models function, or `cv.glm`.

```{r}
library(boot)
```

```{r, eval=FALSE}
?cv.glm
```

Then, apply `cv.glm` function to the `Auto` data set, using `glm_auto` model,
returning the delta parameter.

```{r}
cv.glm(Auto, glm_auto)$delta 
```

We can speed up the results by writing a function to use the formula displayed in section 5.2 (pg. 180) and then pass the `glm_auto` model to it.

```{r}
loocv <- function(x){
          h <- lm.influence(x)$h
        mean((residuals(x)/(1-h))^2)
}
```

Is our new function faster? We can use the `system.time` function to compare both methods.

```{r}
system.time(
cv.glm(Auto, glm_auto)$delta 
)

system.time(
loocv(glm_auto)
)
```

\newpage

Next, lets use a `for` loop to efficiently create 5 new polynomial versions of the previous model, regressing `horsepower` against `mpg` and see if the results improve as polynomial order increases.

```{r}
cv.error <- rep(0, 5)
degree <- 1:5

for(d in degree){
  glm.fit <- glm(mpg ~ poly(horsepower, d), data = Auto)
  cv.error[d] <- loocv(glm.fit)
}

plot(degree, cv.error, type = "b")
```

\newpage

## The10-fold Cross-Validation

```{r}
cv.error10 <- rep(0, 5)

for(d in degree){
  glm.fit <- glm(mpg ~ poly(horsepower, d), data = Auto)
  cv.error10[d] <- cv.glm(Auto, glm.fit, K=10)$delta[1]
}
plot(degree, cv.error, type = "b")
lines(degree,cv.error10, type = "b", col = "red")
```

## Bootstrap

Minimum risk investment fucntion from Section 5.2:

```{r}
alpha <- function(x, y) {
        
          var_x <- var(x)
          var_y <- var(y)
          cov_xy <- cov(x, y)
          (var_y - cov_xy)/(var_x + var_y - 2 *cov_xy)
}

alpha(Portfolio$X, Portfolio$Y)
```

So what is the standard error of alpha?

```{r}
alpha.fn <- function(data, index){
                with(data[index, ], alpha(X, Y))
}

alpha.fn(Portfolio, 1:100)

set.seed(1)
alpha.fn(Portfolio,sample(1:100, 100, replace = TRUE))

boot.out <- boot(Portfolio, alpha.fn, R = 1000)
boot.out$t0

plot(boot.out)
```